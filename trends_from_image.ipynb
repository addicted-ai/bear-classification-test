{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PUBLIC How to detect trends without web scraping.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addicted-ai/fastai-tests/blob/main/trends_from_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTFu1DkncpXi",
        "outputId": "777253f4-ca38-46dc-c1c0-c57670b68207"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (5,347 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/c9/d6e8903482bd6fb994c32722831d15842dd8b614f94ad9ca735807252671/pytesseract-0.3.8.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14071 sha256=8b62b63e7e2b5bf807e03be10903dfe4ece68cc6553e2ed3ffc41fa722d99f8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/66/45/88bf1b2d428817a006944b9730b27d6861b776e05a9e262bd4\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN-DUt02w7Si"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import datetime\n",
        "from IPython.display import Image\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "from hashlib import md5\n",
        "\n",
        "import pytesseract\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx7Nw6Yr9TPP",
        "outputId": "c80aa46b-9ca5-4092-d81e-f41236328ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/fischerbach/fischerbach.github.io.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fischerbach.github.io'...\n",
            "remote: Enumerating objects: 768, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 768 (delta 3), reused 11 (delta 2), pack-reused 753\u001b[K\n",
            "Receiving objects: 100% (768/768), 125.16 MiB | 37.49 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "Checking out files: 100% (732/732), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRgfIbOnALmw"
      },
      "source": [
        "WORK_PATH = '/content/fischerbach.github.io/trend_monitoring'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epPZ5fgTA4Po"
      },
      "source": [
        "def extract_pictures_from_screenshot(filename, output_dir):\n",
        "  minimum_width = 100\n",
        "  minimum_height = 100\n",
        "  \n",
        "  Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  image = cv2.imread(filename)\n",
        "\n",
        "  gray = cv2.cvtColor(image,  cv2.COLOR_BGR2GRAY)\n",
        "  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "  ROI_number = 1\n",
        "  cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "\n",
        "  for c in cnts:\n",
        "     x, y, w, h = cv2.boundingRect(c)\n",
        "     if w >= minimum_width and h >= minimum_height:\n",
        "         ROI = image[y:y+h, x:x+w]\n",
        "         out_image = os.path.join(output_dir, f'{Path(filename).stem}_{ROI_number}.png')\n",
        "         cv2.imwrite(out_image, ROI)\n",
        "         ROI_number += 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9ylaTaRU2ku"
      },
      "source": [
        "def extract_words(filename, verbose=False):\n",
        "  d = pytesseract.image_to_data(Image.open(filename), output_type=pytesseract.Output.DICT)\n",
        "  result = {}\n",
        "  n_boxes = len(d['text'])\n",
        "  for i in range(n_boxes):\n",
        "    word = d['text'][i].strip().lower()\n",
        "    if int(d['conf'][i]) > 60 and len(d['text'][i]) >= 4:\n",
        "      if word not in list(result.keys()):\n",
        "        result[word] = d['width'][i]*d['height'][i]\n",
        "      else:\n",
        "        result[word] += d['width'][i]*d['height'][i]\n",
        "      if(verbose):\n",
        "        display(f\"{word} ==> {result[word]}\")\n",
        "  return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME2fuRkUcpAU"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "def generate_wordcloud(words_dict, output_filename):\n",
        "  text_normalized = {}\n",
        "  text_weights_sum = sum(words_dict.values())\n",
        "  for k, w in words_dict.items():\n",
        "    text_normalized[k] = w  / text_weights_sum\n",
        "  wordcloud = WordCloud(width=4000, height=3000, background_color=\"white\").generate_from_frequencies(text_normalized)\n",
        "  plt.figure(figsize=(40,30))\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.savefig(output_filename)\n",
        "  plt.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED48BH33NQPa"
      },
      "source": [
        "from shutil import copyfile\n",
        "import json\n",
        "\n",
        "def generate_dataset(input_dir):\n",
        "  images = glob.glob(f'{input_dir}/*.png')\n",
        "\n",
        "  for image in images:\n",
        "    date = os.path.basename(image)[:10]\n",
        "    dir = os.path.dirname(image)\n",
        "    out = os.path.join(dir, date)\n",
        "    Path(out).mkdir(parents=True, exist_ok=True)\n",
        "  \n",
        "    copyfile(image, os.path.join(out, os.path.basename(image)))\n",
        "\n",
        "    extract_pictures_from_screenshot(image, os.path.join(out, f'extracted_pictures'))\n",
        "\n",
        "    words = extract_words(image)\n",
        "    with open(os.path.join(out, f'words.json'),\"w\") as words_file:\n",
        "      words_file.write(json.dumps(words))\n",
        "    \n",
        "    generate_wordcloud(words, os.path.join(out, f\"wordcloud_{date}.png\"))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZnY0CUHpnlo"
      },
      "source": [
        "generate_dataset(f'{WORK_PATH}/screenshots/www.bloomberg.com')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfIklUkl82TI"
      },
      "source": [
        "generate_dataset(f'{WORK_PATH}/screenshots/nypost.com')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}